{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Disaster recognition from tweets with deep learning\n",
    "\n",
    "The aim of this project is to create and train a recurrent neural network to recognize disasters from tweets, with high accuracy. The GitHub repository for the project is the following: https://github.com/mohosb/disaster_tweets\n",
    "\n",
    "The data is from the Kaggle competition \"Natural Language Processing with Disaster Tweets\" (https://www.kaggle.com/competitions/nlp-getting-started/overview).\n",
    "\n",
    "In this project I will use PyTorch, a popular deep learning library for Python, and also a package called \"nn_utils\", that contains lots of useful functions. This package is writen and developed entirely by me. (https://github.com/szegedai/nn_utils)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from nn_utils.misc import split_dataset, create_data_loaders\n",
    "from nn_utils.training import train_classifier, CLILoggerCallback"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA\n",
    "\n",
    "In the following cells, we can see that there are 5 columns and 7613 rows. There is a significant amount of missing values in columns \"keyword\" and \"location\". Because of this, it may be beneficial to not use those columns and just simply use the text.\n",
    "\n",
    "There are two possible labels, 0 and 1. These represent if the tweet is about a disaster or not. The balance between the two labels is not ideal, but it is good enough to used reliably in my opinion."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].value_counts().plot(kind='bar', xlabel='Target', ylabel='Count', rot=0);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading, preprocessing and cleaning\n",
    "\n",
    "In this section we will be doing the following:\n",
    "- Load the raw text data\n",
    "- Remove some characters to simplify the task\n",
    "- Break the texts into words/tokens\n",
    "- Build a vocabulary that can be used to create a basic number representation from tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens):\n",
    "        unique_tokens = set(tokens)\n",
    "        self.forward_mapping = dict(zip(unique_tokens, range(1, len(unique_tokens) + 1)))\n",
    "        self.backward_mapping = dict(zip(range(1, len(unique_tokens) + 1), unique_tokens))\n",
    "\n",
    "    def extend(self, tokens):\n",
    "        start_idx = len(self.forward_mapping)\n",
    "        for i, t in enumerate(tokens):\n",
    "            self.forward_mapping[t] = start_idx + i + 1\n",
    "            self.backward_mapping[start_idx + i + 1] = t\n",
    "\n",
    "    def token2idx(self, tokens):\n",
    "        return [self.forward_mapping.get(token, 0) for token in tokens]\n",
    "\n",
    "    def idx2token(self, idxs):\n",
    "        return [self.backward_mapping.get(idx, '<OOV>') for idx in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.forward_mapping) + 1\n",
    "\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, preprocessor=None, with_labels=True):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(path, usecols=['text', 'target'] if with_labels else ['text'])\n",
    "        if preprocessor is not None:\n",
    "            self.df['text'] = self.df['text'].map(preprocessor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return tuple(self.df.iloc[idx].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_text(t):\n",
    "    for c in [',', ':', '.', '!', '?', '#', '@', '\\'', '\\\"']:\n",
    "        t = t.replace(c, '')\n",
    "    t = t.replace('\\n', ' ')\n",
    "    return t.lower()\n",
    "\n",
    "train_ds, val_ds = split_dataset(TweetDataset('./train.csv', clean_text, with_labels=True), split=0.1, seed=42)\n",
    "test_ds = TweetDataset('./test.csv', clean_text, with_labels=False)\n",
    "train_loader, val_loader = create_data_loaders(\n",
    "    [train_ds, val_ds],\n",
    "    batch_size=256, shuffle=True,\n",
    "    num_workers=0, multiprocessing_context=None, persistent_workers=False\n",
    ")\n",
    "test_loader, = create_data_loaders(\n",
    "    [test_ds], batch_size=256, shuffle=False,\n",
    "    num_workers=0, multiprocessing_context=None, persistent_workers=False\n",
    ")\n",
    "\n",
    "tokens = set()\n",
    "for t, _ in iter(train_ds):\n",
    "    tokens.update(t.split(' '))\n",
    "vocab = Vocab(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_text = \\\n",
    "'''This is a simple text to test the tokenization.\n",
    "By the way, all dogs are cute! :D'''\n",
    "vocab.token2idx(clean_text(test_text).split(' '))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model building\n",
    "\n",
    "In the following section we will attempt to build two basic RNN architectures for the classification task. Both will use an embedding layer to transform the basic index based numerical representation of the vocabulary into a higher dimensional representation that is more descriptive of the actual tokens and can be much more useful for the neural network to work with. The embedded vectors will be ran through an LSTM in the first model architecture and a GRU in the case of the other model. The output of the LSTM or GRU will be fed to a simple fully connected layer to make the final classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GRUClassifier(torch.nn.Module):\n",
    "    def __init__(self, preprocessor, vocab, num_classes, embedding_dim, width, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.preprocessor = preprocessor\n",
    "        self.vocab = vocab\n",
    "        self.embedding = torch.nn.Embedding(len(self.vocab), embedding_dim)\n",
    "        self.gru = torch.nn.GRU(embedding_dim, hidden_size=width, batch_first=True)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.classifier = torch.nn.Linear(width, num_classes)\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        self.dtype = torch.float32\n",
    "\n",
    "    def forward(self, text):\n",
    "        tokens = map(lambda t: self.vocab.token2idx(self.preprocessor(t).split(' ')), text)\n",
    "        logits = []\n",
    "        for x in tokens:\n",
    "            x = torch.tensor(x, device=self.device, dtype=torch.int64)[None, :]\n",
    "            x = self.embedding(x)\n",
    "            _, x = self.gru(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.classifier(x[0])\n",
    "            logits.append(x)\n",
    "        return torch.concat(logits, dim=0)\n",
    "\n",
    "    def to(self, device, dtype=None, **kwargs):\n",
    "        self.device = device\n",
    "        if dtype:\n",
    "            self.dtype = dtype\n",
    "        return super().to(device=self.device, dtype=self.dtype, **kwargs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, preprocessor, vocab, num_classes, embedding_dim, width, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.preprocessor = preprocessor\n",
    "        self.vocab = vocab\n",
    "        self.embedding = torch.nn.Embedding(len(self.vocab), embedding_dim)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_size=width, batch_first=True)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.classifier = torch.nn.Linear(width, num_classes)\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        self.dtype = torch.float32\n",
    "\n",
    "    def forward(self, text):\n",
    "        tokens = map(lambda t: self.vocab.token2idx(self.preprocessor(t).split(' ')), text)\n",
    "        logits = []\n",
    "        for x in tokens:\n",
    "            x = torch.tensor(x, device=self.device, dtype=torch.int64)[None, :]\n",
    "            x = self.embedding(x)\n",
    "            _, (x, _) = self.lstm(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.classifier(x[0])\n",
    "            logits.append(x)\n",
    "        return torch.concat(logits, dim=0)\n",
    "\n",
    "    def to(self, device, dtype=None, **kwargs):\n",
    "        self.device = device\n",
    "        if dtype:\n",
    "            self.dtype = dtype\n",
    "        return super().to(device=self.device, dtype=self.dtype, **kwargs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model training any hyperparameter tuning\n",
    "\n",
    "We can play a bit with the different hyperparameters that are learning rate, weight decay, embedding dimension size and hidden layer size. In an ideal situation it is advised to run a full hyperparameter search like a grid search but at this moment I do not have the computational resources to do this, so I will just try a few configurations with a fairly heuristic approach."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Uncomment the device you would like to use!\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('mps')\n",
    "#device = torch.device('cuda')\n",
    "\n",
    "# Uncomment the model you would like to use!\n",
    "#model = LSTMClassifier(clean_text, vocab, num_classes=2, embedding_dim=64, width=128).to(device)\n",
    "#model = GRUClassifier(clean_text, vocab, num_classes=2, embedding_dim=64, width=256).to(device)\n",
    "#model = GRUClassifier(clean_text, vocab, num_classes=2, embedding_dim=128, width=128).to(device)\n",
    "#model = GRUClassifier(clean_text, vocab, num_classes=2, embedding_dim=256, width=128).to(device)\n",
    "model = GRUClassifier(clean_text, vocab, num_classes=2, embedding_dim=576, width=128).to(device)\n",
    "#model = GRUClassifier(clean_text, vocab, num_classes=2, embedding_dim=1024, width=256).to(device)\n",
    "\n",
    "# Uncomment the optimizer you would like to use!\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.005)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_classifier(model, loss_fn, optimizer, train_loader, val_loader,\n",
    "                 callbacks=[\n",
    "                     CLILoggerCallback()\n",
    "                 ], num_epochs=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results and conclusion\n",
    "\n",
    "| model type | learning rate | weight decay | embedding dimension | hidden layers width | number of epochs | validation accuracy |\n",
    "|------------|---------------|--------------|---------------------|---------------------|------------------|---------------------|\n",
    "| lstm       | 0.001         | 0.0001       | 64                  | 128                 | 3                | 66.23%              |\n",
    "| gru        | 0.001         | 0.0001       | 64                  | 128                 | 3                | 70.04%              |\n",
    "| gru        | 0.001         | 0.0001       | 64                  | 256                 | 3                | 65.57%              |\n",
    "| gru        | 0.001         | 0.001        | 64                  | 256                 | 3                | 66.10%              |\n",
    "| gru        | 0.001         | 0.001        | 64                  | 128                 | 3                | 70.83%              |\n",
    "| gru        | 0.001         | 0.001        | 128                 | 128                 | 3                | 71.35%              |\n",
    "| gru        | 0.001         | 0.005        | 128                 | 128                 | 3                | 72.54%              |\n",
    "| gru        | 0.001         | 0.01         | 128                 | 128                 | 3                | 69.78%              |\n",
    "| gru        | 0.001         | 0.01         | 256                 | 128                 | 3                | 73.32%              |\n",
    "| gru        | 0.001         | 0.01         | 512                 | 128                 | 3                | 74.90%              |\n",
    "| gru        | 0.01          | 0.01         | 512                 | 128                 | 1                | 77.79%              |\n",
    "(Rerunning the trainings may not produce the exact same results because of the random nature of the network initialization.)\n",
    "\n",
    "Overfitting was the biggest problem during the trainings. First off, LSTM showed much more overfitting by default which is not to surprising since it is a bit of an overcomplicated architecture. Because of this I chose to use GRU for every other test. Despite this, ovefitting remained a big trouble. Increasing the number of neurons in the hidden layers, significantly increases the training accuracy, but the at the same time, decreases the validation accuracy, this is why I chose to keep the 128. To combat the overfitting, I started to increase the weight decay and the embedding dimension size. After that, I noticed that the first epoch always has the best validation accuracy, so for my last training I used only 1 epoch.\n",
    "\n",
    "In conclusion, the model was improved significantly by just playing with the hyperparameters, but I am sure that a much better configuration could be found with the appropriate amount of hyperparameters searching."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_ids = pd.read_csv('./test.csv', usecols=['id']).values[:, 0]\n",
    "all_predictions = []\n",
    "model.eval()\n",
    "for text, in test_loader:\n",
    "    all_predictions += model(text).argmax(dim=1).to(dtype=torch.int).tolist()\n",
    "submission = pd.DataFrame({'id': all_ids, 'target': all_predictions})\n",
    "submission.to_csv('submission.csv', sep=',', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
